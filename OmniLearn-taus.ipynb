{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94bc0944-e298-4d08-b42e-8fcafda114fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:14:25.704471: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-03 15:14:25.704494: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-03 15:14:25.704520: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-03 15:14:25.710123: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"scripts\")\n",
    "import utils\n",
    "from PET import PET\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83a2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496a64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward\n",
    "import vector\n",
    "\n",
    "def to_p4(p4_obj):\n",
    "    return vector.awk(\n",
    "        awkward.zip(\n",
    "            {\n",
    "                \"mass\": p4_obj.tau,\n",
    "                \"x\": p4_obj.x,\n",
    "                \"y\": p4_obj.y,\n",
    "                \"z\": p4_obj.z,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "def deltaphi(phi1, phi2):\n",
    "    diff = phi1 - phi2\n",
    "    return np.arctan2(np.sin(diff), np.cos(diff))\n",
    "\n",
    "def deltar(eta1, phi1, eta2, phi2):\n",
    "    deta = eta1 - eta2\n",
    "    dphi = deltaphi(phi1, phi2)\n",
    "    return np.sqrt(deta**2 + dphi**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6befe447-e662-4229-a30f-73902740eb4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:14:29.543405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.551605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.553018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.555331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.556775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.558105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.680301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.682060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.683551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-03 15:14:29.684714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6646 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = PET(\n",
    "    num_feat=13,\n",
    "    num_jet=4,\n",
    "    num_classes=10,\n",
    "    local=True,\n",
    "    num_layers=8,\n",
    "    drop_probability=0,\n",
    "    simple=False,\n",
    "    layer_scale=True,\n",
    "    talking_head=False,\n",
    "    mode=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e701f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 (32, 100, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py:642: UserWarning: Input dict contained keys ['input_jet'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    }
   ],
   "source": [
    "x = {}\n",
    "x[\"input_features\"] = tf.zeros((32, 100, 13))\n",
    "x[\"input_points\"] = tf.zeros((32, 100, 2))\n",
    "x[\"input_mask\"] = tf.zeros((32, 100))\n",
    "x[\"input_jet\"] = tf.zeros((32, 4))\n",
    "x[\"input_time\"] = tf.zeros((32, 1))\n",
    "\n",
    "model(x)\n",
    "out = model.body(x)\n",
    "print(len(out), out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca000ed4-2aa9-4a77-8de0-2a58b289eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " PET_body (Functional)       (None, None, 128)         1318784   \n",
      "                                                                 \n",
      " classifier_head (Functiona  [(None, 10),              269326    \n",
      " l)                           (None, 4)]                         \n",
      "                                                                 \n",
      " generator_head (Functional  (None, None, 13)          417165    \n",
      " )                                                               \n",
      "                                                                 \n",
      " classifier (Functional)     [(None, 10),              1588110   \n",
      "                              (None, 4)]                         \n",
      "                                                                 \n",
      " generator (Functional)      (None, None, 13)          1735949   \n",
      "                                                                 \n",
      " ema (Functional)            (None, None, 128)         1318784   \n",
      "                                                                 \n",
      " ema_head (Functional)       (None, None, 13)          417165    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3741236 (14.27 MB)\n",
      "Trainable params: 3741224 (14.27 MB)\n",
      "Non-trainable params: 12 (48.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.load_weights(\"checkpoints/PET_jetclass_8_local_layer_scale_token_baseline_all.weights.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311ae706",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = awkward.from_parquet(\"../ml-tau-en-reg/data/zh.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b8d352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/awkward/_nplikes/array_module.py:245: RuntimeWarning: divide by zero encountered in log\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "/usr/local/lib/python3.10/dist-packages/awkward/_nplikes/array_module.py:245: RuntimeWarning: invalid value encountered in log\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    }
   ],
   "source": [
    "reco_cand_p4s = to_p4(data[\"reco_cand_p4s\"])\n",
    "reco_jet_p4s = to_p4(data[\"reco_jet_p4s\"])\n",
    "\n",
    "delta_eta = reco_cand_p4s.eta - reco_jet_p4s.eta\n",
    "delta_phi = deltaphi(reco_cand_p4s.phi, reco_jet_p4s.phi)\n",
    "log_pt = np.log(reco_cand_p4s.pt)\n",
    "log_e = np.log(reco_cand_p4s.energy)\n",
    "log_ptjet = np.log(1 - reco_cand_p4s.pt/reco_jet_p4s.pt)\n",
    "log_ejet = np.log(1 - reco_cand_p4s.energy/reco_jet_p4s.energy)\n",
    "delta_r = deltar(reco_cand_p4s.eta, reco_cand_p4s.phi, reco_jet_p4s.eta, reco_jet_p4s.phi)\n",
    "charge = data[\"reco_cand_charge\"]\n",
    "is_ele = np.abs(data[\"reco_cand_pdg\"])==11\n",
    "is_mu = np.abs(data[\"reco_cand_pdg\"])==13\n",
    "is_photon = np.abs(data[\"reco_cand_pdg\"])==22\n",
    "is_chhad = np.abs(data[\"reco_cand_pdg\"])==210\n",
    "is_nhad = np.abs(data[\"reco_cand_pdg\"])==130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e7a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = 64 #max number of particles per jet\n",
    "fill_val = 0 #fill value of padded data\n",
    "\n",
    "#create particle array in the shape [njets, pad_size, 13]\n",
    "vals = [\n",
    "    awkward.to_numpy(\n",
    "        awkward.fill_none(\n",
    "            awkward.pad_none(\n",
    "                x, pad_size, clip=True), fill_val\n",
    "        )\n",
    "    ) for x in [delta_eta, delta_phi, log_pt, log_e, log_ptjet, log_ejet, delta_r, charge, is_ele, is_mu, is_photon, is_chhad, is_nhad]\n",
    "]\n",
    "particles = np.stack(vals, axis=-1)\n",
    "particles[np.isnan(particles)] = 0\n",
    "particles[np.isinf(particles)] = 0\n",
    "particles_mask = (~awkward.to_numpy(awkward.pad_none(delta_eta, pad_size, clip=True)).mask).astype(np.float32)\n",
    "\n",
    "#normalize particles\n",
    "means_particle = particles[np.squeeze(particles_mask==1)].mean(axis=0)\n",
    "stds_particle = particles[np.squeeze(particles_mask==1)].std(axis=0)\n",
    "stds_particle[stds_particle==0] = 1\n",
    "particles = (particles - means_particle)/stds_particle\n",
    "\n",
    "#create jet array in the shape [njets, 4]\n",
    "jets = awkward.to_numpy(np.stack([\n",
    "    reco_jet_p4s.pt,\n",
    "    reco_jet_p4s.eta,\n",
    "    reco_jet_p4s.mass,\n",
    "    awkward.num(reco_cand_p4s)], axis=-1)\n",
    ")\n",
    "jets[np.isnan(jets)] = 0\n",
    "jets[np.isinf(jets)] = 0\n",
    "\n",
    "#normalize jets\n",
    "means_jet = jets.mean(axis=0)\n",
    "stds_jet = jets.std(axis=0)\n",
    "stds_jet[stds_jet==0] = 1\n",
    "jets = (jets - means_jet)/stds_jet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7381908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.81484866e-04, -4.42451595e-04,  1.64661402e+00,  1.91612564e+00,\n",
       "        -3.49537160e-01, -5.56091975e-01,  8.88749957e-02,  2.68606613e-04,\n",
       "         1.65204057e-02,  1.70791603e-03,  4.93146355e-01,  0.00000000e+00,\n",
       "         1.08669180e-01]),\n",
       " array([0.10679366, 0.12574273, 1.65159405, 1.54891286, 0.63094431,\n",
       "        1.98268285, 0.13898771, 0.63101854, 0.12746561, 0.04129163,\n",
       "        0.49995303, 1.        , 0.3112237 ]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_particle, stds_particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f89f1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.16619602e+01, -4.30674452e-04,  3.52147311e+00,  4.28605183e+00]),\n",
       " array([32.83552096,  0.68882761,  4.5377347 ,  3.19867077]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_jet, stds_jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c4486af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((530722, 64, 13), (530722, 64), (530722, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles.shape, particles_mask.shape, jets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313a47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = awkward.to_numpy(data[\"gen_jet_tau_decaymode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc147e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(start, stop):\n",
    "    x = {}\n",
    "    x[\"input_features\"] = particles[start:stop]\n",
    "    x[\"input_points\"] = particles[start:stop, :, :2]\n",
    "    x[\"input_mask\"] = np.expand_dims(particles_mask[start:stop], axis=-1)\n",
    "    x[\"input_jet\"] = jets[start:stop]\n",
    "    x[\"input_time\"] = np.zeros((stop-start, 1))\n",
    "    y = targets[start:stop]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f9c0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from layers import StochasticDepth, TalkingHeadAttention, LayerScale, RandomDrop\n",
    "\n",
    "def get_encoding(x, projection_dim, use_bias=True):\n",
    "    x = layers.Dense(2*projection_dim, use_bias=use_bias, activation='gelu')(x)\n",
    "    x = layers.Dense(projection_dim, use_bias=use_bias, activation='gelu')(x)\n",
    "    return x\n",
    "\n",
    "def FourierProjection(x,projection_dim,num_embed=64):    \n",
    "    half_dim = num_embed // 2\n",
    "    emb = tf.math.log(10000.0) / (half_dim - 1)\n",
    "    emb = tf.cast(emb,tf.float32)\n",
    "    freq = tf.exp(-emb* tf.range(start=0, limit=half_dim, dtype=tf.float32))\n",
    "\n",
    "\n",
    "    angle = x*freq*1000.0\n",
    "    embedding = tf.concat([tf.math.sin(angle),tf.math.cos(angle)],-1)*x\n",
    "    embedding = layers.Dense(2*projection_dim,activation=\"swish\",use_bias=False)(embedding)\n",
    "    embedding = layers.Dense(projection_dim,activation=\"swish\",use_bias=False)(embedding)\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def knn(num_points, k, topk_indices, features):\n",
    "    # topk_indices: (N, P, K)\n",
    "    # features: (N, P, C)    \n",
    "    batch_size = tf.shape(features)[0]\n",
    "\n",
    "    batch_indices = tf.reshape(tf.range(batch_size), (-1, 1, 1))\n",
    "    batch_indices = tf.tile(batch_indices, (1, num_points, k))\n",
    "    indices = tf.stack([batch_indices, topk_indices], axis=-1)\n",
    "    return tf.gather_nd(features, indices)\n",
    "\n",
    "def get_neighbors(points,features,projection_dim,K):\n",
    "    drij = pairwise_distance(points)  # (N, P, P)\n",
    "    _, indices = tf.nn.top_k(-drij, k=K + 1)  # (N, P, K+1)\n",
    "    indices = indices[:, :, 1:]  # (N, P, K)\n",
    "    knn_fts = knn(tf.shape(points)[1], K, indices, features)  # (N, P, K, C)\n",
    "    knn_fts_center = tf.broadcast_to(tf.expand_dims(features, 2), tf.shape(knn_fts))\n",
    "    local = tf.concat([knn_fts-knn_fts_center,knn_fts_center],-1)\n",
    "    local = layers.Dense(2*projection_dim,activation='gelu')(local)\n",
    "    local = layers.Dense(projection_dim,activation='gelu')(local)\n",
    "    local = tf.reduce_mean(local,-2)\n",
    "    \n",
    "    return local\n",
    "\n",
    "def pairwise_distance(point_cloud):\n",
    "    r = tf.reduce_sum(point_cloud * point_cloud, axis=2, keepdims=True)\n",
    "    m = tf.matmul(point_cloud, point_cloud, transpose_b = True)\n",
    "    D = r - 2 * m + tf.transpose(r, perm=(0, 2, 1)) + 1e-5\n",
    "    return D\n",
    "\n",
    "\n",
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self,\n",
    "                 use_backbone,\n",
    "                 num_feat,\n",
    "                 num_jet,      \n",
    "                 num_classes=2):\n",
    "        \n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.projection_dim = model.projection_dim\n",
    "        self.num_heads = model.num_heads\n",
    "        \n",
    "        self.feature_drop = model.feature_drop\n",
    "        self.num_keep = model.num_keep\n",
    "        self.mode = model.mode\n",
    "        self.num_layers = model.num_layers\n",
    "        self.layer_scale = model.layer_scale\n",
    "        self.layer_scale_init = model.layer_scale_init\n",
    "        self.drop_probability = model.drop_probability\n",
    "        self.dropout = model.dropout\n",
    "        \n",
    "        self._input_features = layers.Input(shape=(None, num_feat), name='input_features')\n",
    "        self._input_points = layers.Input(shape=(None, 2), name='input_points')\n",
    "        self._input_mask = layers.Input(shape=(None, 1), name='input_mask')\n",
    "        self._input_jet = layers.Input((num_jet, ),name='input_jet')\n",
    "        self._input_time = layers.Input((None, ),name='input_time')\n",
    "\n",
    "        if use_backbone:\n",
    "            self.backbone_body = self.PET_body(\n",
    "                self._input_features,\n",
    "                self._input_points,\n",
    "                self._input_mask,\n",
    "                self._input_time,\n",
    "                True,\n",
    "                10,\n",
    "                2,\n",
    "                False\n",
    "            )\n",
    "            self.backbone = keras.Model(\n",
    "                inputs=[self._input_features, self._input_points, self._input_mask, self._input_time],\n",
    "                outputs=[self.backbone_body], name=\"backbone\"\n",
    "            )\n",
    "\n",
    "            particles_encoded = self.backbone_body\n",
    "        else:\n",
    "            particles_encoded = get_encoding(self._input_features, self.projection_dim)\n",
    "\n",
    "        for ilayer in range(2):\n",
    "            updates = layers.MultiHeadAttention(\n",
    "                num_heads=self.num_heads,\n",
    "                key_dim=self.projection_dim//self.num_heads)(\n",
    "                query=particles_encoded, value=particles_encoded, key=particles_encoded)\n",
    "            particles_encoded = layers.Add()([updates, particles_encoded])\n",
    "            particles_encoded = layers.GroupNormalization(groups=1)(particles_encoded)\n",
    "            particles_encoded = layers.Dense(self.projection_dim)(particles_encoded)\n",
    "        \n",
    "        representation = layers.GlobalAveragePooling1D()(particles_encoded)\n",
    "        jet_encoded = get_encoding(self._input_jet, self.projection_dim)\n",
    "        representation = layers.Dense(self.projection_dim,activation='gelu')(representation+jet_encoded)\n",
    "        outputs_dm_pred = layers.Dense(num_classes, activation=\"softmax\")(representation)\n",
    "        \n",
    "        self.decaymode_head = keras.Model(\n",
    "            inputs=[self._input_features, self._input_points, self._input_mask, self._input_jet, self._input_time],\n",
    "            outputs=[outputs_dm_pred], name=\"decaymode_head\"\n",
    "        )\n",
    "\n",
    "    def PET_body(self,\n",
    "                 input_features,\n",
    "                 input_points,\n",
    "                 input_mask,\n",
    "                 input_time,\n",
    "                 local, K,num_local,\n",
    "                 talking_head,\n",
    "                 ):\n",
    "            \n",
    "        #Randomly drop features not present in other datasets\n",
    "        encoded = RandomDrop(self.feature_drop if  'all' in self.mode else 0.0,num_skip=self.num_keep)(input_features)                        \n",
    "        encoded = get_encoding(encoded,self.projection_dim)\n",
    "\n",
    "        time = FourierProjection(input_time,self.projection_dim)\n",
    "        time = tf.tile(time[:,None, :], [1,tf.shape(encoded)[1], 1])*input_mask\n",
    "        time = layers.Dense(2*self.projection_dim,activation='gelu',use_bias=False)(time)\n",
    "        scale,shift = tf.split(time,2,-1)\n",
    "        \n",
    "        encoded = encoded*(1.0+scale) + shift\n",
    "        \n",
    "        if local:\n",
    "            coord_shift = tf.multiply(999., tf.cast(tf.equal(input_mask, 0), dtype='float32'))        \n",
    "            points = input_points[:,:,:2]\n",
    "            local_features = input_features\n",
    "            for _ in range(num_local):\n",
    "                local_features = get_neighbors(coord_shift+points,local_features,self.projection_dim,K)\n",
    "                points = local_features\n",
    "                \n",
    "            encoded = layers.Add()([local_features,encoded])\n",
    "\n",
    "        skip_connection = encoded\n",
    "        for i in range(self.num_layers):\n",
    "            x1 = layers.GroupNormalization(groups=1)(encoded)\n",
    "            if talking_head:\n",
    "                updates, _ = TalkingHeadAttention(self.projection_dim, self.num_heads, 0.0)(x1)\n",
    "            else:\n",
    "                updates = layers.MultiHeadAttention(num_heads=self.num_heads,\n",
    "                                                    key_dim=self.projection_dim//self.num_heads)(x1,x1)\n",
    "\n",
    "            if self.layer_scale:\n",
    "                updates = LayerScale(self.layer_scale_init, self.projection_dim)(updates,input_mask)\n",
    "            updates = StochasticDepth(self.drop_probability)(updates)\n",
    "            x2 = layers.Add()([updates,encoded])\n",
    "            x3 = layers.GroupNormalization(groups=1)(x2)\n",
    "            x3 = layers.Dense(2*self.projection_dim,activation=\"gelu\")(x3)\n",
    "            x3 = layers.Dropout(self.dropout)(x3)\n",
    "            x3 = layers.Dense(self.projection_dim)(x3)\n",
    "            if self.layer_scale:\n",
    "                x3 = LayerScale(self.layer_scale_init, self.projection_dim)(x3,input_mask)\n",
    "            x3 = StochasticDepth(self.drop_probability)(x3)\n",
    "            encoded = layers.Add()([x3,x2])*input_mask\n",
    "        return encoded + skip_connection\n",
    "    \n",
    "    def call(self, x):\n",
    "        ret = self.decaymode_head([\n",
    "            x[\"input_features\"], x[\"input_points\"], x[\"input_mask\"], x[\"input_jet\"], x[\"input_time\"]\n",
    "        ])\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac03962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dm_direct = TransformerModel(False, 13, 4, 16)\n",
    "x, y = prepare_data(0, 256)\n",
    "model_dm_direct(x)\n",
    "\n",
    "model_dm_bb = TransformerModel(True, 13, 4, 16)\n",
    "x, y = prepare_data(0, 256)\n",
    "model_dm_bb(x)\n",
    "model_dm_bb.backbone.set_weights(model.body.weights)\n",
    "model_dm_bb.backbone.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5a10b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decaymode_head (Functional  (None, 16)                254864    \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254864 (995.56 KB)\n",
      "Trainable params: 254864 (995.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dm_direct.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43dd0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(0, 50000)\n",
    "X_val, y_val = prepare_data(50000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6a3780a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:14:49.322190: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bbc6087b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-03 15:14:49.322209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060 SUPER, Compute Capability 7.5\n",
      "2024-05-03 15:14:49.326389: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-03 15:14:49.340490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-05-03 15:14:49.389165: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 9s 27ms/step - loss: 1.1603 - val_loss: 0.7274\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.6181 - val_loss: 0.5616\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.5309 - val_loss: 0.5105\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4969 - val_loss: 0.4851\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4734 - val_loss: 0.4699\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4538 - val_loss: 0.4646\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4470 - val_loss: 0.4440\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4349 - val_loss: 0.4407\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4299 - val_loss: 0.4280\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 5s 23ms/step - loss: 0.4225 - val_loss: 0.4283\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4156 - val_loss: 0.4239\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4131 - val_loss: 0.4148\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4070 - val_loss: 0.4131\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4054 - val_loss: 0.4213\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.4022 - val_loss: 0.4171\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3983 - val_loss: 0.4117\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3964 - val_loss: 0.3998\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3927 - val_loss: 0.4032\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3894 - val_loss: 0.4052\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3862 - val_loss: 0.3967\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3842 - val_loss: 0.3974\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3838 - val_loss: 0.3956\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3803 - val_loss: 0.3943\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3772 - val_loss: 0.4194\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3744 - val_loss: 0.3892\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3730 - val_loss: 0.3921\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3693 - val_loss: 0.3835\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3689 - val_loss: 0.3810\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3667 - val_loss: 0.3810\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3635 - val_loss: 0.3770\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3630 - val_loss: 0.3775\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3604 - val_loss: 0.3736\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3583 - val_loss: 0.3878\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3573 - val_loss: 0.3838\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3554 - val_loss: 0.3770\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3532 - val_loss: 0.3692\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3524 - val_loss: 0.3722\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3511 - val_loss: 0.3688\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3498 - val_loss: 0.3675\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3497 - val_loss: 0.3793\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3464 - val_loss: 0.3653\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3464 - val_loss: 0.3691\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3449 - val_loss: 0.3786\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3456 - val_loss: 0.3675\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3437 - val_loss: 0.3689\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3426 - val_loss: 0.3647\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3403 - val_loss: 0.3687\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3405 - val_loss: 0.3649\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3382 - val_loss: 0.3670\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3380 - val_loss: 0.3648\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3374 - val_loss: 0.3651\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3365 - val_loss: 0.3661\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3356 - val_loss: 0.3577\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3330 - val_loss: 0.3606\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3336 - val_loss: 0.3675\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3328 - val_loss: 0.3649\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3315 - val_loss: 0.3679\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3317 - val_loss: 0.3602\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3304 - val_loss: 0.3604\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3286 - val_loss: 0.3591\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3275 - val_loss: 0.3564\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3273 - val_loss: 0.3548\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3262 - val_loss: 0.3565\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3256 - val_loss: 0.3548\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3245 - val_loss: 0.3536\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3236 - val_loss: 0.3603\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3236 - val_loss: 0.3544\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3214 - val_loss: 0.3548\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3216 - val_loss: 0.3578\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3197 - val_loss: 0.3559\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3202 - val_loss: 0.3603\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3201 - val_loss: 0.3586\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3198 - val_loss: 0.3572\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3185 - val_loss: 0.3567\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3167 - val_loss: 0.3560\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3161 - val_loss: 0.3533\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3147 - val_loss: 0.3558\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3141 - val_loss: 0.3539\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3141 - val_loss: 0.3576\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3130 - val_loss: 0.3545\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3129 - val_loss: 0.3565\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3113 - val_loss: 0.3555\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3108 - val_loss: 0.3550\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3120 - val_loss: 0.3541\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3099 - val_loss: 0.3537\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3095 - val_loss: 0.3545\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3083 - val_loss: 0.3605\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3077 - val_loss: 0.3548\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3065 - val_loss: 0.3539\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3049 - val_loss: 0.3569\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3057 - val_loss: 0.3544\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3050 - val_loss: 0.3570\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3051 - val_loss: 0.3566\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3036 - val_loss: 0.3620\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3038 - val_loss: 0.3574\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3012 - val_loss: 0.3576\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.3013 - val_loss: 0.3513\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.2996 - val_loss: 0.3563\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.2993 - val_loss: 0.3623\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 5s 24ms/step - loss: 0.2998 - val_loss: 0.3578\n"
     ]
    }
   ],
   "source": [
    "model_dm_direct.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    ")\n",
    "history = model_dm_direct.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "223854c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x71ddb0691870>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6bc1042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " backbone (Functional)       (None, None, 128)         1318784   \n",
      "                                                                 \n",
      " decaymode_head (Functional  (None, 16)                1537168   \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1537168 (5.86 MB)\n",
      "Trainable params: 218384 (853.06 KB)\n",
      "Non-trainable params: 1318784 (5.03 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dm_bb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 56s 244ms/step - loss: 1.2484 - val_loss: 0.9857\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.8240 - val_loss: 0.7151\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.6544 - val_loss: 0.6081\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.5740 - val_loss: 0.5617\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.5397 - val_loss: 0.5628\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.5183 - val_loss: 0.5294\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.5041 - val_loss: 0.4980\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4858 - val_loss: 0.4995\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4765 - val_loss: 0.4977\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4677 - val_loss: 0.4769\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4661 - val_loss: 0.5026\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4575 - val_loss: 0.5032\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4483 - val_loss: 0.4867\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4463 - val_loss: 0.4587\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4411 - val_loss: 0.4551\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4391 - val_loss: 0.4772\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4404 - val_loss: 0.4530\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4330 - val_loss: 0.4583\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4349 - val_loss: 0.4448\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4238 - val_loss: 0.4483\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4258 - val_loss: 0.4343\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4224 - val_loss: 0.5244\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4198 - val_loss: 0.4397\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4205 - val_loss: 0.4609\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4191 - val_loss: 0.4299\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 46s 235ms/step - loss: 0.4137 - val_loss: 0.4343\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4096 - val_loss: 0.4390\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4112 - val_loss: 0.4306\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4093 - val_loss: 0.4506\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 46s 236ms/step - loss: 0.4067 - val_loss: 0.4430\n",
      "Epoch 31/100\n",
      "145/196 [=====================>........] - ETA: 6s - loss: 0.4048"
     ]
    }
   ],
   "source": [
    "model_dm_bb.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    ")\n",
    "history2 = model_dm_bb.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history[\"loss\"])\n",
    "plt.plot(history2.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b90291",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"direct\", color=\"black\")\n",
    "plt.plot(history2.history[\"loss\"], label=\"OmniLearn backbone\", color=\"red\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8049ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
